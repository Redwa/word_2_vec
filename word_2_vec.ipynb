{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Word2Vec Model on the Reddit Comments Dataset\n",
    "\n",
    "### Ravish Chawla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first start with the necessary imports. For this project, we will need NLTK (for nlp), Gensim (for Word2Vec), SkLearn (for a clustering algorithm), Pandas and Numby (for data structures and processing), and some other libraries that will will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import nltk.data;\n",
    "\n",
    "from gensim.models import word2vec;\n",
    "\n",
    "from sklearn.cluster import KMeans;\n",
    "from sklearn.neighbors import KDTree;\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "\n",
    "import os;\n",
    "import re;\n",
    "import logging;\n",
    "import sqlite3;\n",
    "import time;\n",
    "import sys;\n",
    "import multiprocessing;\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt;\n",
    "from itertools import cycle;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From NLTK, we need to download the package \"Punkt\", which contains a module for obtaining sentences from a text. The package needs to be downloaded first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ravishchawla/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset I am using is the Reddit May2015 Comments data, avalaible on Kaggle here: http://kaggle.com/reddit/reddit-comments-may-2015\n",
    "\n",
    "Since the data is in a .sqlite format, we will open up a sql connection to read it from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sql_con = sqlite3.connect('/mnt/big/data/database.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a note, the dataset is very large in size (8 gb compressed / 30 gb uncompressed). I suggest that you use a machine that has sufficient RAM for processing. For my implementation, I ran the notebook on an AWS P4.2xLarge instance, with 60GB RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 82.60828137397766 secs\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "sql_data = pd.read_sql(\"SELECT body FROM May2015\", sql_con);\n",
    "print('Total time: ' + str((time.time() - start)) + ' secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54504410\n"
     ]
    }
   ],
   "source": [
    "total_rows = len(sql_data);\n",
    "print(total_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are around 55,000,000 individual comments in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Punkt package from NLTK, we obtain a String tokenizer. The tokenizer allows us to feed it comments and obtain individual sentences in it. It'll be used as part of pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function will be called on the comments, and will clean the data. We will apply several pre-processing steps to it.\n",
    "\n",
    "1. Remove all escape-tabs and escape-newlines\n",
    "2. Remove all non symbol characters (except for the dot)\n",
    "3. Normalize spaces to a single character\n",
    "4. Remove leading and trailing spaces\n",
    "5. Tokenizing the text into sentences\n",
    "\n",
    "Because it takes a long time to clean the entire comments data, the function has been written to take a file name as an argument. Instead of saving the cleaned text in memory, it will be written to this file instead, to help avoid a kernel crash in case the process runs out of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(all_comments, out_name):\n",
    "    \n",
    "    out_file = open(out_name, 'w');\n",
    "    \n",
    "    for pos in range(len(all_comments)):\n",
    "    \n",
    "        #Get the comment\n",
    "        val = all_comments.iloc[pos]['body'];\n",
    "        \n",
    "        #Normalize tabs and remove newlines\n",
    "        no_tabs = str(val).replace('\\t', ' ').replace('\\n', '');\n",
    "        \n",
    "        #Remove all characters except A-Z and a dot.\n",
    "        alphas_only = re.sub(\"[^a-zA-Z\\.]\", \" \", no_tabs);\n",
    "        \n",
    "        #Normalize spaces to 1\n",
    "        multi_spaces = re.sub(\" +\", \" \", alphas_only);\n",
    "        \n",
    "        #Strip trailing and leading spaces\n",
    "        no_spaces = multi_spaces.strip();\n",
    "        \n",
    "        #Normalize all charachters to lowercase\n",
    "        clean_text = no_spaces.lower();\n",
    "        \n",
    "        #Get sentences from the tokenizer, remove the dot in each.\n",
    "        sentences = tokenizer.tokenize(clean_text);\n",
    "        sentences = [re.sub(\"[\\.]\", \"\", sentence) for sentence in sentences];\n",
    "        \n",
    "        #If the text has more than one space (removing single word comments) and one character, write it to the file.\n",
    "        if len(clean_text) > 0 and clean_text.count(' ') > 0:\n",
    "            for sentence in sentences:\n",
    "                out_file.write(\"%s\\n\" % sentence)\n",
    "                print(sentence);\n",
    "                \n",
    "        #Simple logging. At every 50000th step,\n",
    "        #print the total number of rows processed and time taken so far, and flush the file.\n",
    "        if pos % 50000 == 0:\n",
    "            total_time = time.time() - start;\n",
    "            sys.stdout.write('Completed ' + str(round(100 * (pos / total_rows), 2)) + '% - ' + str(pos) + ' rows in time ' + str(round(total_time / 60, 0)) + ' min & ' + str(round(total_time % 60, 2)) + ' secs\\r');\n",
    "            out_file.flush();\n",
    "            break;\n",
    "        \n",
    "    out_file.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took about 5 hours to clean the entire dataset. After having completed the pre-processing, the output file contained clean sentences with no symbols, uppercase letters, leading, trailing, or multi spaces, and escape charachters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 16183.129625082016 secs time 270.0 min & 41.12 secs\n"
     ]
    }
   ],
   "source": [
    "start = time.time();\n",
    "clean_comments = clean_text(sql_data, '/mnt/big/out_full')\n",
    "print('Total time: ' + str((time.time() - start)) + ' secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will train the Word2Vec model on the cleaned sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time();\n",
    "\n",
    "#Set the logging format to get some basic updates.\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 100;    # Dimensionality of the hidden layer representation\n",
    "min_word_count = 40;   # Minimum word count to keep a word in the vocabulary\n",
    "num_workers = multiprocessing.cpu_count();       # Number of threads to run in parallel set to total number of cpus.\n",
    "context = 5          # Context window size (on each side)                                                       \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model. \n",
    "#The LineSentence object allows us to pass in a file name directly as input to Word2Vec,\n",
    "#instead of having to read it into memory first.\n",
    "\n",
    "print(\"Training model...\");\n",
    "model = word2vec.Word2Vec(LineSentence('/mnt/big/out_full_clean'), workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling);\n",
    "\n",
    "# We don't plan on training the model any further, so calling \n",
    "# init_sims will make the model more memory efficient by normalizing the vectors in-place.\n",
    "model.init_sims(replace=True);\n",
    "\n",
    "# Save the model\n",
    "model_name = \"model_full_reddit\";\n",
    "model.save(model_name);\n",
    "\n",
    "print('Total time: ' + str((time.time() - start)) + ' secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec.load('model_full_reddit');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we obtain the Word Vectors for each word in the vocab, stored in a variable called 'syn0':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = model.wv.syn0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.11665151, -0.049594  ,  0.11327834,  0.07592423, -0.04993806,\n",
       "        0.1568293 , -0.1132786 ,  0.22942989,  0.00898544, -0.28502461,\n",
       "        0.03516449,  0.08205829, -0.03942069, -0.00534692,  0.06644268,\n",
       "       -0.00625445, -0.00066186, -0.07234078,  0.03497642, -0.01976413,\n",
       "        0.01201833,  0.1050311 , -0.00342888, -0.18235329, -0.02376735,\n",
       "       -0.02839357, -0.1606423 , -0.00285926,  0.13409872,  0.06622207,\n",
       "       -0.10163352,  0.0105407 , -0.0997504 ,  0.06160791,  0.11051619,\n",
       "        0.17395724,  0.04719392, -0.07631388, -0.10458953, -0.0071361 ,\n",
       "       -0.01559975, -0.05712711,  0.02177166,  0.17927928, -0.05927899,\n",
       "       -0.03273784,  0.04689875, -0.11919602, -0.10765067, -0.08047853,\n",
       "        0.1568861 ,  0.07896987, -0.18372187,  0.07167481, -0.17768474,\n",
       "        0.05764568, -0.04963266,  0.05483604,  0.10472295, -0.04929474,\n",
       "        0.04694352, -0.14964867, -0.00282077, -0.11832199, -0.05498586,\n",
       "        0.05160207,  0.0822202 ,  0.23181327,  0.08466525,  0.07332655,\n",
       "        0.0221282 ,  0.03846532, -0.05099594,  0.00453909,  0.10295779,\n",
       "        0.10701912, -0.00672292,  0.12998071,  0.10565597,  0.16730358,\n",
       "        0.08564204, -0.0385814 , -0.0275824 ,  0.08518873, -0.01272774,\n",
       "        0.14785041,  0.04440513, -0.09262343,  0.23331712, -0.05708617,\n",
       "        0.03630534,  0.11807019, -0.11764669,  0.01931123, -0.03500355,\n",
       "        0.00498019,  0.07433683,  0.09522536,  0.08134035,  0.18196103], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Z[0].shape)\n",
    "Z[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the word vector for the first word, we see a 100-element vector with values updated after training the neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will analyze the results of the algorithms in different ways, to see what we can do with Word2Vec. The first thing we will do is cluster the words using KMeans. Since the Words are represented as vectors, applying KMeans is easy to do since the clustering algorithm will simply look at differences between vectors (and centers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clustering_on_wordvecs(word_vectors, num_clusters):\n",
    "    # Initalize a k-means object and use it to extract centroids\n",
    "    kmeans_clustering = KMeans(n_clusters = num_clusters, init='k-means++');\n",
    "    idx = kmeans_clustering.fit_predict(word_vectors);\n",
    "    \n",
    "    return kmeans_clustering.cluster_centers_, idx;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 257.2132160663605 secs\n"
     ]
    }
   ],
   "source": [
    "start = time.time();\n",
    "centers, clusters = clustering_on_wordvecs(Z, 50);\n",
    "print('Total time: ' + str((time.time() - start)) + ' secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.10984086990356445 secs\n"
     ]
    }
   ],
   "source": [
    "start = time.time();\n",
    "centroid_map = dict(zip(model.wv.index2word, clusters));\n",
    "print('Total time: ' + str((time.time() - start)) + ' secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we get words in each cluster that are closest to the cluster center. To do this, we initialize a KDTree on the word vectors, and query it for the Top K words on each cluster center. Using the Index 2 word dictionary, we than correspond each word vector back to it's original word representation and add them to a dataframe for easier printiing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_words(index2word, k, centers, wordvecs):\n",
    "    tree = KDTree(wordvecs);\n",
    "\n",
    "    #Closest points for each Cluster center is used to query the closest 20 points to it.\n",
    "    closest_points = [tree.query(np.reshape(x, (1, -1)), k=k) for x in centers];\n",
    "    closest_words_idxs = [x[1] for x in closest_points];\n",
    "\n",
    "    #Word Index is queried for each position in the above array, and added to a Dictionary.\n",
    "    closest_words = {};\n",
    "    for i in range(0, len(closest_words_idxs)):\n",
    "        closest_words['Cluster #' + str(i+1).zfill(2)] = [index2word[j] for j in closest_words_idxs[i][0]]\n",
    "\n",
    "    #A DataFrame is generated from the dictionary.\n",
    "    df = pd.DataFrame(closest_words);\n",
    "    df.index = df.index+1\n",
    "\n",
    "    return df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_words = get_top_words(model.wv.index2word, 20, centers, Z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster #01</th>\n",
       "      <th>Cluster #02</th>\n",
       "      <th>Cluster #03</th>\n",
       "      <th>Cluster #04</th>\n",
       "      <th>Cluster #05</th>\n",
       "      <th>Cluster #06</th>\n",
       "      <th>Cluster #07</th>\n",
       "      <th>Cluster #08</th>\n",
       "      <th>Cluster #09</th>\n",
       "      <th>Cluster #10</th>\n",
       "      <th>Cluster #11</th>\n",
       "      <th>Cluster #12</th>\n",
       "      <th>Cluster #13</th>\n",
       "      <th>Cluster #14</th>\n",
       "      <th>Cluster #15</th>\n",
       "      <th>Cluster #16</th>\n",
       "      <th>Cluster #17</th>\n",
       "      <th>Cluster #18</th>\n",
       "      <th>Cluster #19</th>\n",
       "      <th>Cluster #20</th>\n",
       "      <th>Cluster #21</th>\n",
       "      <th>Cluster #22</th>\n",
       "      <th>Cluster #23</th>\n",
       "      <th>Cluster #24</th>\n",
       "      <th>Cluster #25</th>\n",
       "      <th>Cluster #26</th>\n",
       "      <th>Cluster #27</th>\n",
       "      <th>Cluster #28</th>\n",
       "      <th>Cluster #29</th>\n",
       "      <th>Cluster #30</th>\n",
       "      <th>Cluster #31</th>\n",
       "      <th>Cluster #32</th>\n",
       "      <th>Cluster #33</th>\n",
       "      <th>Cluster #34</th>\n",
       "      <th>Cluster #35</th>\n",
       "      <th>Cluster #36</th>\n",
       "      <th>Cluster #37</th>\n",
       "      <th>Cluster #38</th>\n",
       "      <th>Cluster #39</th>\n",
       "      <th>Cluster #40</th>\n",
       "      <th>Cluster #41</th>\n",
       "      <th>Cluster #42</th>\n",
       "      <th>Cluster #43</th>\n",
       "      <th>Cluster #44</th>\n",
       "      <th>Cluster #45</th>\n",
       "      <th>Cluster #46</th>\n",
       "      <th>Cluster #47</th>\n",
       "      <th>Cluster #48</th>\n",
       "      <th>Cluster #49</th>\n",
       "      <th>Cluster #50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exwife</td>\n",
       "      <td>echando</td>\n",
       "      <td>csk</td>\n",
       "      <td>nymphs</td>\n",
       "      <td>slithers</td>\n",
       "      <td>benson</td>\n",
       "      <td>nedir</td>\n",
       "      <td>undermining</td>\n",
       "      <td>thingsthere</td>\n",
       "      <td>mallninjashit</td>\n",
       "      <td>cyklister</td>\n",
       "      <td>pltzjrhgif</td>\n",
       "      <td>thanksi</td>\n",
       "      <td>secretion</td>\n",
       "      <td>warbringer</td>\n",
       "      <td>weap</td>\n",
       "      <td>nightso</td>\n",
       "      <td>hmrc</td>\n",
       "      <td>buttermilk</td>\n",
       "      <td>rhineland</td>\n",
       "      <td>fastback</td>\n",
       "      <td>bellonas</td>\n",
       "      <td>materialism</td>\n",
       "      <td>archivehtml</td>\n",
       "      <td>badbadnotgood</td>\n",
       "      <td>trouwens</td>\n",
       "      <td>ranma</td>\n",
       "      <td>awesomenauts</td>\n",
       "      <td>missles</td>\n",
       "      <td>riverside</td>\n",
       "      <td>cucks</td>\n",
       "      <td>ambigram</td>\n",
       "      <td>valeur</td>\n",
       "      <td>ebenfalls</td>\n",
       "      <td>besler</td>\n",
       "      <td>hahahaah</td>\n",
       "      <td>turnigy</td>\n",
       "      <td>catainia</td>\n",
       "      <td>confine</td>\n",
       "      <td>eviscerated</td>\n",
       "      <td>appunto</td>\n",
       "      <td>oscillations</td>\n",
       "      <td>druddigon</td>\n",
       "      <td>interestingit</td>\n",
       "      <td>pleather</td>\n",
       "      <td>flemeth</td>\n",
       "      <td>noastre</td>\n",
       "      <td>chegou</td>\n",
       "      <td>nmap</td>\n",
       "      <td>rzg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tormentors</td>\n",
       "      <td>adecuada</td>\n",
       "      <td>mous</td>\n",
       "      <td>spiny</td>\n",
       "      <td>bobbed</td>\n",
       "      <td>welch</td>\n",
       "      <td>cevap</td>\n",
       "      <td>belittles</td>\n",
       "      <td>oddballs</td>\n",
       "      <td>swordorsheath</td>\n",
       "      <td>fyller</td>\n",
       "      <td>dhmeazkgif</td>\n",
       "      <td>dudei</td>\n",
       "      <td>corticosteroids</td>\n",
       "      <td>rattleclaw</td>\n",
       "      <td>godsword</td>\n",
       "      <td>nightit</td>\n",
       "      <td>commission</td>\n",
       "      <td>curd</td>\n",
       "      <td>macedonia</td>\n",
       "      <td>hardtop</td>\n",
       "      <td>gnars</td>\n",
       "      <td>scientism</td>\n",
       "      <td>dxdoiorg</td>\n",
       "      <td>thundercat</td>\n",
       "      <td>slechts</td>\n",
       "      <td>gintoki</td>\n",
       "      <td>homm</td>\n",
       "      <td>grenadiers</td>\n",
       "      <td>hampden</td>\n",
       "      <td>misogynist</td>\n",
       "      <td>antipattern</td>\n",
       "      <td>lalcool</td>\n",
       "      <td>verfahren</td>\n",
       "      <td>coyle</td>\n",
       "      <td>yaaaa</td>\n",
       "      <td>frsky</td>\n",
       "      <td>wpintheshower</td>\n",
       "      <td>expose</td>\n",
       "      <td>savaged</td>\n",
       "      <td>peggio</td>\n",
       "      <td>redshift</td>\n",
       "      <td>noibat</td>\n",
       "      <td>offputting</td>\n",
       "      <td>neoprene</td>\n",
       "      <td>odysseus</td>\n",
       "      <td>acasa</td>\n",
       "      <td>mestrado</td>\n",
       "      <td>plugin</td>\n",
       "      <td>zbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ladyfriend</td>\n",
       "      <td>revisar</td>\n",
       "      <td>anderlecht</td>\n",
       "      <td>jellyfish</td>\n",
       "      <td>flapped</td>\n",
       "      <td>byrne</td>\n",
       "      <td>devam</td>\n",
       "      <td>pursues</td>\n",
       "      <td>thingsthey</td>\n",
       "      <td>treessuckingonthings</td>\n",
       "      <td>idioter</td>\n",
       "      <td>tjabjjlgif</td>\n",
       "      <td>heyi</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>stoneforge</td>\n",
       "      <td>vagan</td>\n",
       "      <td>nightbut</td>\n",
       "      <td>fincen</td>\n",
       "      <td>soya</td>\n",
       "      <td>jordanian</td>\n",
       "      <td>cyl</td>\n",
       "      <td>meele</td>\n",
       "      <td>conceptualization</td>\n",
       "      <td>didthemarinerswincom</td>\n",
       "      <td>bjork</td>\n",
       "      <td>gebeurt</td>\n",
       "      <td>gosick</td>\n",
       "      <td>nwn</td>\n",
       "      <td>javelin</td>\n",
       "      <td>lakewood</td>\n",
       "      <td>mysoginistic</td>\n",
       "      <td>lpwo</td>\n",
       "      <td>choisi</td>\n",
       "      <td>wenigstens</td>\n",
       "      <td>boozer</td>\n",
       "      <td>ohhhhhhhhh</td>\n",
       "      <td>sanyo</td>\n",
       "      <td>xgykbfcd</td>\n",
       "      <td>supplant</td>\n",
       "      <td>overtaken</td>\n",
       "      <td>diritto</td>\n",
       "      <td>diffusion</td>\n",
       "      <td>slugma</td>\n",
       "      <td>importantbut</td>\n",
       "      <td>beaded</td>\n",
       "      <td>boromir</td>\n",
       "      <td>incepe</td>\n",
       "      <td>conseguiram</td>\n",
       "      <td>commandline</td>\n",
       "      <td>oyz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daugher</td>\n",
       "      <td>maravilloso</td>\n",
       "      <td>jaedong</td>\n",
       "      <td>lizards</td>\n",
       "      <td>wiggled</td>\n",
       "      <td>connelly</td>\n",
       "      <td>eka</td>\n",
       "      <td>defends</td>\n",
       "      <td>oddities</td>\n",
       "      <td>subredditsashashtags</td>\n",
       "      <td>fortsatt</td>\n",
       "      <td>drhiqrgifv</td>\n",
       "      <td>hahahai</td>\n",
       "      <td>corticosteroid</td>\n",
       "      <td>rakshasa</td>\n",
       "      <td>masamune</td>\n",
       "      <td>nightthis</td>\n",
       "      <td>ird</td>\n",
       "      <td>wasabi</td>\n",
       "      <td>burma</td>\n",
       "      <td>mkiv</td>\n",
       "      <td>udyrs</td>\n",
       "      <td>praxeology</td>\n",
       "      <td>blognavercom</td>\n",
       "      <td>yelawolf</td>\n",
       "      <td>meestal</td>\n",
       "      <td>xxxholic</td>\n",
       "      <td>skullgirls</td>\n",
       "      <td>ballista</td>\n",
       "      <td>decatur</td>\n",
       "      <td>tumblerina</td>\n",
       "      <td>antivaxxer</td>\n",
       "      <td>suivre</td>\n",
       "      <td>niemals</td>\n",
       "      <td>briere</td>\n",
       "      <td>ayye</td>\n",
       "      <td>jvc</td>\n",
       "      <td>gijose</td>\n",
       "      <td>rationalise</td>\n",
       "      <td>cannibalized</td>\n",
       "      <td>mantenere</td>\n",
       "      <td>perturbation</td>\n",
       "      <td>spiritomb</td>\n",
       "      <td>commonand</td>\n",
       "      <td>ultrafine</td>\n",
       "      <td>mordred</td>\n",
       "      <td>undeva</td>\n",
       "      <td>noite</td>\n",
       "      <td>xampp</td>\n",
       "      <td>vww</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shipmates</td>\n",
       "      <td>tremenda</td>\n",
       "      <td>galatasaray</td>\n",
       "      <td>tadpoles</td>\n",
       "      <td>darted</td>\n",
       "      <td>mckay</td>\n",
       "      <td>olmu</td>\n",
       "      <td>denigrates</td>\n",
       "      <td>counterexamples</td>\n",
       "      <td>shubreddit</td>\n",
       "      <td>ordentligt</td>\n",
       "      <td>drhiqr</td>\n",
       "      <td>yesi</td>\n",
       "      <td>isotretinoin</td>\n",
       "      <td>nighthowler</td>\n",
       "      <td>veng</td>\n",
       "      <td>edcny</td>\n",
       "      <td>cmhc</td>\n",
       "      <td>buckwheat</td>\n",
       "      <td>sultanate</td>\n",
       "      <td>peugeot</td>\n",
       "      <td>swains</td>\n",
       "      <td>nihilism</td>\n",
       "      <td>inceptiondavepeducom</td>\n",
       "      <td>bangarang</td>\n",
       "      <td>eruit</td>\n",
       "      <td>idolmaster</td>\n",
       "      <td>dcuo</td>\n",
       "      <td>miniguns</td>\n",
       "      <td>pasadena</td>\n",
       "      <td>humourless</td>\n",
       "      <td>idiotbut</td>\n",
       "      <td>lacte</td>\n",
       "      <td>dennoch</td>\n",
       "      <td>haula</td>\n",
       "      <td>yaaaaa</td>\n",
       "      <td>boscam</td>\n",
       "      <td>ellesarisellendil</td>\n",
       "      <td>constrain</td>\n",
       "      <td>hounded</td>\n",
       "      <td>figlio</td>\n",
       "      <td>cmb</td>\n",
       "      <td>moltres</td>\n",
       "      <td>unproffesional</td>\n",
       "      <td>cowhide</td>\n",
       "      <td>moqorro</td>\n",
       "      <td>tocmai</td>\n",
       "      <td>acabou</td>\n",
       "      <td>winscp</td>\n",
       "      <td>qhw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wifeand</td>\n",
       "      <td>prioridad</td>\n",
       "      <td>huk</td>\n",
       "      <td>clownfish</td>\n",
       "      <td>scooting</td>\n",
       "      <td>dunne</td>\n",
       "      <td>saat</td>\n",
       "      <td>disrespects</td>\n",
       "      <td>gotchas</td>\n",
       "      <td>theydidthemonstermath</td>\n",
       "      <td>staden</td>\n",
       "      <td>imzhell</td>\n",
       "      <td>yeai</td>\n",
       "      <td>cipro</td>\n",
       "      <td>gravekeepers</td>\n",
       "      <td>danjuro</td>\n",
       "      <td>nightalso</td>\n",
       "      <td>underwriting</td>\n",
       "      <td>applesauce</td>\n",
       "      <td>macedonian</td>\n",
       "      <td>silverado</td>\n",
       "      <td>ulty</td>\n",
       "      <td>dialectic</td>\n",
       "      <td>blogcom</td>\n",
       "      <td>qotsa</td>\n",
       "      <td>vaker</td>\n",
       "      <td>adachi</td>\n",
       "      <td>titanfall</td>\n",
       "      <td>decimator</td>\n",
       "      <td>ashland</td>\n",
       "      <td>trannies</td>\n",
       "      <td>assholealso</td>\n",
       "      <td>devait</td>\n",
       "      <td>jedoch</td>\n",
       "      <td>wisniewski</td>\n",
       "      <td>nawww</td>\n",
       "      <td>emax</td>\n",
       "      <td>deckwash</td>\n",
       "      <td>verbalize</td>\n",
       "      <td>bested</td>\n",
       "      <td>soprattutto</td>\n",
       "      <td>spectroscopy</td>\n",
       "      <td>audino</td>\n",
       "      <td>irksome</td>\n",
       "      <td>peacoat</td>\n",
       "      <td>faramir</td>\n",
       "      <td>acestea</td>\n",
       "      <td>fugir</td>\n",
       "      <td>libc</td>\n",
       "      <td>vyt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>friendyou</td>\n",
       "      <td>castigo</td>\n",
       "      <td>stephano</td>\n",
       "      <td>reindeer</td>\n",
       "      <td>bobbing</td>\n",
       "      <td>siegel</td>\n",
       "      <td>amk</td>\n",
       "      <td>sabotages</td>\n",
       "      <td>thigns</td>\n",
       "      <td>thingsjonsnowknows</td>\n",
       "      <td>metoder</td>\n",
       "      <td>adibprojpg</td>\n",
       "      <td>youstill</td>\n",
       "      <td>idiopathic</td>\n",
       "      <td>banefire</td>\n",
       "      <td>tyro</td>\n",
       "      <td>nightand</td>\n",
       "      <td>icbc</td>\n",
       "      <td>jalapeno</td>\n",
       "      <td>mughals</td>\n",
       "      <td>wrangler</td>\n",
       "      <td>dravens</td>\n",
       "      <td>universality</td>\n",
       "      <td>momspaghettiytmndcom</td>\n",
       "      <td>madvillainy</td>\n",
       "      <td>aardig</td>\n",
       "      <td>takahashi</td>\n",
       "      <td>firefall</td>\n",
       "      <td>machinegun</td>\n",
       "      <td>lexington</td>\n",
       "      <td>libtard</td>\n",
       "      <td>overexaggeration</td>\n",
       "      <td>vacances</td>\n",
       "      <td>daraus</td>\n",
       "      <td>cassels</td>\n",
       "      <td>yooooo</td>\n",
       "      <td>kenwood</td>\n",
       "      <td>japface</td>\n",
       "      <td>subvert</td>\n",
       "      <td>outvoted</td>\n",
       "      <td>scienza</td>\n",
       "      <td>capacitance</td>\n",
       "      <td>dedenne</td>\n",
       "      <td>importantedit</td>\n",
       "      <td>tulle</td>\n",
       "      <td>conquerer</td>\n",
       "      <td>scurt</td>\n",
       "      <td>risco</td>\n",
       "      <td>dmenu</td>\n",
       "      <td>qgc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sexlife</td>\n",
       "      <td>electorado</td>\n",
       "      <td>fener</td>\n",
       "      <td>caterpillars</td>\n",
       "      <td>wiggling</td>\n",
       "      <td>mcgrath</td>\n",
       "      <td>degil</td>\n",
       "      <td>victimizing</td>\n",
       "      <td>afscs</td>\n",
       "      <td>girlsmirin</td>\n",
       "      <td>saken</td>\n",
       "      <td>vwmingif</td>\n",
       "      <td>matei</td>\n",
       "      <td>hypoglycemia</td>\n",
       "      <td>thragtusk</td>\n",
       "      <td>weaps</td>\n",
       "      <td>nightedit</td>\n",
       "      <td>financing</td>\n",
       "      <td>chutney</td>\n",
       "      <td>rhodesia</td>\n",
       "      <td>supra</td>\n",
       "      <td>trynd</td>\n",
       "      <td>amorality</td>\n",
       "      <td>mainhtml</td>\n",
       "      <td>motown</td>\n",
       "      <td>gedrag</td>\n",
       "      <td>saki</td>\n",
       "      <td>terraria</td>\n",
       "      <td>needler</td>\n",
       "      <td>charleston</td>\n",
       "      <td>feminazi</td>\n",
       "      <td>antijoke</td>\n",
       "      <td>tudier</td>\n",
       "      <td>ndlich</td>\n",
       "      <td>osuna</td>\n",
       "      <td>ooohhhhh</td>\n",
       "      <td>denon</td>\n",
       "      <td>deeprocks</td>\n",
       "      <td>satisfy</td>\n",
       "      <td>intimated</td>\n",
       "      <td>diverso</td>\n",
       "      <td>scalar</td>\n",
       "      <td>heracross</td>\n",
       "      <td>believeable</td>\n",
       "      <td>goretex</td>\n",
       "      <td>circe</td>\n",
       "      <td>noaptea</td>\n",
       "      <td>profissionais</td>\n",
       "      <td>openssl</td>\n",
       "      <td>zja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stepbrother</td>\n",
       "      <td>mitad</td>\n",
       "      <td>villareal</td>\n",
       "      <td>squirrels</td>\n",
       "      <td>twirled</td>\n",
       "      <td>delaney</td>\n",
       "      <td>yine</td>\n",
       "      <td>demonizing</td>\n",
       "      <td>usecases</td>\n",
       "      <td>shittyanimalfacts</td>\n",
       "      <td>resultatet</td>\n",
       "      <td>slcrftmbsgs</td>\n",
       "      <td>broi</td>\n",
       "      <td>etoh</td>\n",
       "      <td>wyrm</td>\n",
       "      <td>ukanlos</td>\n",
       "      <td>bonaroo</td>\n",
       "      <td>superannuation</td>\n",
       "      <td>jalepeno</td>\n",
       "      <td>kyrgyz</td>\n",
       "      <td>hemi</td>\n",
       "      <td>serqets</td>\n",
       "      <td>nonviolence</td>\n",
       "      <td>fontsspddlde</td>\n",
       "      <td>kygo</td>\n",
       "      <td>ouders</td>\n",
       "      <td>gantz</td>\n",
       "      <td>archeage</td>\n",
       "      <td>skyguard</td>\n",
       "      <td>acadia</td>\n",
       "      <td>misanthropes</td>\n",
       "      <td>idiotalso</td>\n",
       "      <td>hension</td>\n",
       "      <td>ebenso</td>\n",
       "      <td>coghlan</td>\n",
       "      <td>yeaaaaah</td>\n",
       "      <td>vrx</td>\n",
       "      <td>michaelconfoy</td>\n",
       "      <td>weaponize</td>\n",
       "      <td>cockblocked</td>\n",
       "      <td>attivit</td>\n",
       "      <td>quantization</td>\n",
       "      <td>girafarig</td>\n",
       "      <td>interestingits</td>\n",
       "      <td>rhinestones</td>\n",
       "      <td>eowyn</td>\n",
       "      <td>totusi</td>\n",
       "      <td>estudante</td>\n",
       "      <td>robocopy</td>\n",
       "      <td>gjq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wifei</td>\n",
       "      <td>hacerles</td>\n",
       "      <td>fenerbahce</td>\n",
       "      <td>moth</td>\n",
       "      <td>flicked</td>\n",
       "      <td>farrar</td>\n",
       "      <td>fazla</td>\n",
       "      <td>dehumanizes</td>\n",
       "      <td>scps</td>\n",
       "      <td>retiredgifs</td>\n",
       "      <td>kapitalismen</td>\n",
       "      <td>yvviq</td>\n",
       "      <td>bruhi</td>\n",
       "      <td>inflammation</td>\n",
       "      <td>spellbreaker</td>\n",
       "      <td>hadar</td>\n",
       "      <td>edclv</td>\n",
       "      <td>fdic</td>\n",
       "      <td>edamame</td>\n",
       "      <td>yemeni</td>\n",
       "      <td>gsxr</td>\n",
       "      <td>sylv</td>\n",
       "      <td>postmodernism</td>\n",
       "      <td>feedsfeedburnercom</td>\n",
       "      <td>zedd</td>\n",
       "      <td>aangezien</td>\n",
       "      <td>yoshiki</td>\n",
       "      <td>nosgoth</td>\n",
       "      <td>recce</td>\n",
       "      <td>piedmont</td>\n",
       "      <td>dudebros</td>\n",
       "      <td>underachiever</td>\n",
       "      <td>gouvernements</td>\n",
       "      <td>vollkommen</td>\n",
       "      <td>kaman</td>\n",
       "      <td>ayyyyyyy</td>\n",
       "      <td>spektrum</td>\n",
       "      <td>vinciisdead</td>\n",
       "      <td>eradicate</td>\n",
       "      <td>squelched</td>\n",
       "      <td>spesa</td>\n",
       "      <td>conformal</td>\n",
       "      <td>wobbuffet</td>\n",
       "      <td>annoyingi</td>\n",
       "      <td>ripstop</td>\n",
       "      <td>saruman</td>\n",
       "      <td>cuvinte</td>\n",
       "      <td>roubar</td>\n",
       "      <td>sqlite</td>\n",
       "      <td>qjx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bestfriend</td>\n",
       "      <td>pongan</td>\n",
       "      <td>momochi</td>\n",
       "      <td>tarantula</td>\n",
       "      <td>fluttered</td>\n",
       "      <td>clements</td>\n",
       "      <td>fakat</td>\n",
       "      <td>dismisses</td>\n",
       "      <td>thingspeople</td>\n",
       "      <td>ooerintensifies</td>\n",
       "      <td>historien</td>\n",
       "      <td>fruomifpw</td>\n",
       "      <td>ireally</td>\n",
       "      <td>urticaria</td>\n",
       "      <td>smiter</td>\n",
       "      <td>rath</td>\n",
       "      <td>otakon</td>\n",
       "      <td>insurers</td>\n",
       "      <td>sorbet</td>\n",
       "      <td>algeria</td>\n",
       "      <td>busa</td>\n",
       "      <td>ulti</td>\n",
       "      <td>subjectivism</td>\n",
       "      <td>wwwbashorg</td>\n",
       "      <td>flylo</td>\n",
       "      <td>neemt</td>\n",
       "      <td>inuyasha</td>\n",
       "      <td>tropico</td>\n",
       "      <td>broadsides</td>\n",
       "      <td>waterford</td>\n",
       "      <td>xenophobe</td>\n",
       "      <td>ambivert</td>\n",
       "      <td>rarement</td>\n",
       "      <td>anscheinend</td>\n",
       "      <td>montero</td>\n",
       "      <td>ahahahahahahaha</td>\n",
       "      <td>vsr</td>\n",
       "      <td>brazilsamba</td>\n",
       "      <td>desensitize</td>\n",
       "      <td>courted</td>\n",
       "      <td>diciamo</td>\n",
       "      <td>convolution</td>\n",
       "      <td>tropius</td>\n",
       "      <td>neckbeardy</td>\n",
       "      <td>quilted</td>\n",
       "      <td>grima</td>\n",
       "      <td>asemenea</td>\n",
       "      <td>levam</td>\n",
       "      <td>sdl</td>\n",
       "      <td>qln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>motheri</td>\n",
       "      <td>reciben</td>\n",
       "      <td>skc</td>\n",
       "      <td>anemones</td>\n",
       "      <td>slithering</td>\n",
       "      <td>dougherty</td>\n",
       "      <td>mieli</td>\n",
       "      <td>antagonizing</td>\n",
       "      <td>monikers</td>\n",
       "      <td>natureismetal</td>\n",
       "      <td>delvis</td>\n",
       "      <td>tqzgqegjpg</td>\n",
       "      <td>exactlyi</td>\n",
       "      <td>curcumin</td>\n",
       "      <td>evilswarm</td>\n",
       "      <td>chameleos</td>\n",
       "      <td>gbo</td>\n",
       "      <td>comission</td>\n",
       "      <td>pistachio</td>\n",
       "      <td>punjab</td>\n",
       "      <td>ducati</td>\n",
       "      <td>kogs</td>\n",
       "      <td>fatalism</td>\n",
       "      <td>instantostrichcom</td>\n",
       "      <td>avicii</td>\n",
       "      <td>ontzettend</td>\n",
       "      <td>chobits</td>\n",
       "      <td>mabinogi</td>\n",
       "      <td>autocannon</td>\n",
       "      <td>alameda</td>\n",
       "      <td>hatemongers</td>\n",
       "      <td>assholebut</td>\n",
       "      <td>suivi</td>\n",
       "      <td>moderatoren</td>\n",
       "      <td>lofton</td>\n",
       "      <td>yeaahhh</td>\n",
       "      <td>lumenier</td>\n",
       "      <td>tortoisesex</td>\n",
       "      <td>overwhelm</td>\n",
       "      <td>waylaid</td>\n",
       "      <td>pensiero</td>\n",
       "      <td>conductivity</td>\n",
       "      <td>cyndaquil</td>\n",
       "      <td>boringedit</td>\n",
       "      <td>linen</td>\n",
       "      <td>rheagar</td>\n",
       "      <td>vorbesc</td>\n",
       "      <td>animais</td>\n",
       "      <td>cli</td>\n",
       "      <td>qfw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stepson</td>\n",
       "      <td>seguiremos</td>\n",
       "      <td>hungrybox</td>\n",
       "      <td>crabs</td>\n",
       "      <td>flicking</td>\n",
       "      <td>doherty</td>\n",
       "      <td>uzun</td>\n",
       "      <td>condemning</td>\n",
       "      <td>thingsnow</td>\n",
       "      <td>itwasagraveyardgraph</td>\n",
       "      <td>enormt</td>\n",
       "      <td>wjanvcdjpg</td>\n",
       "      <td>xdi</td>\n",
       "      <td>estrogens</td>\n",
       "      <td>deciever</td>\n",
       "      <td>shotel</td>\n",
       "      <td>campout</td>\n",
       "      <td>irs</td>\n",
       "      <td>cornbread</td>\n",
       "      <td>zapatistas</td>\n",
       "      <td>landcruiser</td>\n",
       "      <td>malzahars</td>\n",
       "      <td>dogmatism</td>\n",
       "      <td>kckst</td>\n",
       "      <td>nujabes</td>\n",
       "      <td>daadwerkelijk</td>\n",
       "      <td>kaiki</td>\n",
       "      <td>teso</td>\n",
       "      <td>gunboats</td>\n",
       "      <td>edgewater</td>\n",
       "      <td>douchenozzles</td>\n",
       "      <td>lise</td>\n",
       "      <td>largement</td>\n",
       "      <td>immerhin</td>\n",
       "      <td>henrique</td>\n",
       "      <td>yeeee</td>\n",
       "      <td>monoprice</td>\n",
       "      <td>feckingshite</td>\n",
       "      <td>expel</td>\n",
       "      <td>assailed</td>\n",
       "      <td>posizione</td>\n",
       "      <td>emission</td>\n",
       "      <td>seviper</td>\n",
       "      <td>difficultand</td>\n",
       "      <td>mohair</td>\n",
       "      <td>gwyn</td>\n",
       "      <td>scriu</td>\n",
       "      <td>feita</td>\n",
       "      <td>builtin</td>\n",
       "      <td>rzp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bodyand</td>\n",
       "      <td>fecha</td>\n",
       "      <td>mineski</td>\n",
       "      <td>tortoise</td>\n",
       "      <td>wriggling</td>\n",
       "      <td>spence</td>\n",
       "      <td>olur</td>\n",
       "      <td>manipulates</td>\n",
       "      <td>knuckleheads</td>\n",
       "      <td>lifeofnorman</td>\n",
       "      <td>vinst</td>\n",
       "      <td>vqlgjolgif</td>\n",
       "      <td>uhi</td>\n",
       "      <td>acetaminophen</td>\n",
       "      <td>recombobulator</td>\n",
       "      <td>emberblade</td>\n",
       "      <td>nightfor</td>\n",
       "      <td>treasury</td>\n",
       "      <td>cashew</td>\n",
       "      <td>czechoslovak</td>\n",
       "      <td>powerstroke</td>\n",
       "      <td>katarinas</td>\n",
       "      <td>dialectics</td>\n",
       "      <td>embedgyazocom</td>\n",
       "      <td>blackmill</td>\n",
       "      <td>ergens</td>\n",
       "      <td>shinobu</td>\n",
       "      <td>wakfu</td>\n",
       "      <td>minigun</td>\n",
       "      <td>grandview</td>\n",
       "      <td>douchbag</td>\n",
       "      <td>exageration</td>\n",
       "      <td>faute</td>\n",
       "      <td>weiterhin</td>\n",
       "      <td>callahan</td>\n",
       "      <td>aaaw</td>\n",
       "      <td>cdj</td>\n",
       "      <td>stalkingbutler</td>\n",
       "      <td>micromanage</td>\n",
       "      <td>repelled</td>\n",
       "      <td>immigrati</td>\n",
       "      <td>invariant</td>\n",
       "      <td>seedot</td>\n",
       "      <td>accuratealso</td>\n",
       "      <td>pewter</td>\n",
       "      <td>craster</td>\n",
       "      <td>oricum</td>\n",
       "      <td>ficou</td>\n",
       "      <td>qgis</td>\n",
       "      <td>hzy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>soulmate</td>\n",
       "      <td>sobretodo</td>\n",
       "      <td>besiktas</td>\n",
       "      <td>dungeness</td>\n",
       "      <td>swishing</td>\n",
       "      <td>mccall</td>\n",
       "      <td>niye</td>\n",
       "      <td>vilifying</td>\n",
       "      <td>subjects</td>\n",
       "      <td>humansbeingbros</td>\n",
       "      <td>konstant</td>\n",
       "      <td>irspheerbj</td>\n",
       "      <td>thatlol</td>\n",
       "      <td>reflux</td>\n",
       "      <td>felguard</td>\n",
       "      <td>soultaker</td>\n",
       "      <td>tomorrowworld</td>\n",
       "      <td>hhs</td>\n",
       "      <td>tabasco</td>\n",
       "      <td>kashmir</td>\n",
       "      <td>sportster</td>\n",
       "      <td>yasuos</td>\n",
       "      <td>empiricism</td>\n",
       "      <td>thatsthejokenet</td>\n",
       "      <td>deadmau</td>\n",
       "      <td>waarschijnlijk</td>\n",
       "      <td>shizuo</td>\n",
       "      <td>helldivers</td>\n",
       "      <td>chaingun</td>\n",
       "      <td>lafayette</td>\n",
       "      <td>feminazis</td>\n",
       "      <td>lisis</td>\n",
       "      <td>essaye</td>\n",
       "      <td>deutschlands</td>\n",
       "      <td>mccarron</td>\n",
       "      <td>yeeah</td>\n",
       "      <td>teac</td>\n",
       "      <td>nappyzap</td>\n",
       "      <td>outsmart</td>\n",
       "      <td>supplanted</td>\n",
       "      <td>attuale</td>\n",
       "      <td>cyclic</td>\n",
       "      <td>zangoose</td>\n",
       "      <td>disapointing</td>\n",
       "      <td>nubuck</td>\n",
       "      <td>moriah</td>\n",
       "      <td>experienta</td>\n",
       "      <td>entretanto</td>\n",
       "      <td>dirsync</td>\n",
       "      <td>vqu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>castmates</td>\n",
       "      <td>dignidad</td>\n",
       "      <td>ludogorets</td>\n",
       "      <td>dragonflies</td>\n",
       "      <td>darting</td>\n",
       "      <td>olson</td>\n",
       "      <td>belki</td>\n",
       "      <td>antagonizes</td>\n",
       "      <td>things</td>\n",
       "      <td>retiredjpg</td>\n",
       "      <td>kroppen</td>\n",
       "      <td>bennotronica</td>\n",
       "      <td>yupi</td>\n",
       "      <td>hyperglycemia</td>\n",
       "      <td>manamorphose</td>\n",
       "      <td>zanbato</td>\n",
       "      <td>pmso</td>\n",
       "      <td>liquidation</td>\n",
       "      <td>habanero</td>\n",
       "      <td>armenia</td>\n",
       "      <td>kawi</td>\n",
       "      <td>kalistas</td>\n",
       "      <td>physicalism</td>\n",
       "      <td>nonref</td>\n",
       "      <td>wavves</td>\n",
       "      <td>ineens</td>\n",
       "      <td>dekomori</td>\n",
       "      <td>exanima</td>\n",
       "      <td>melta</td>\n",
       "      <td>norfolk</td>\n",
       "      <td>misogynists</td>\n",
       "      <td>injoke</td>\n",
       "      <td>ouverte</td>\n",
       "      <td>mittlerweile</td>\n",
       "      <td>brodeur</td>\n",
       "      <td>yeaah</td>\n",
       "      <td>vtx</td>\n",
       "      <td>hossannna</td>\n",
       "      <td>persuade</td>\n",
       "      <td>flogged</td>\n",
       "      <td>piuttosto</td>\n",
       "      <td>covariance</td>\n",
       "      <td>crawdaunt</td>\n",
       "      <td>niave</td>\n",
       "      <td>selvage</td>\n",
       "      <td>gandalf</td>\n",
       "      <td>altceva</td>\n",
       "      <td>criminalidade</td>\n",
       "      <td>tftp</td>\n",
       "      <td>qqj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nmother</td>\n",
       "      <td>digna</td>\n",
       "      <td>lemondogs</td>\n",
       "      <td>grasshoppers</td>\n",
       "      <td>glided</td>\n",
       "      <td>mcelroy</td>\n",
       "      <td>yoksa</td>\n",
       "      <td>mistreating</td>\n",
       "      <td>exbeeriments</td>\n",
       "      <td>noisygifs</td>\n",
       "      <td>argumentet</td>\n",
       "      <td>consciousblankamericancicada</td>\n",
       "      <td>whoai</td>\n",
       "      <td>sinusitis</td>\n",
       "      <td>soulshift</td>\n",
       "      <td>ceadeus</td>\n",
       "      <td>dragoncon</td>\n",
       "      <td>disbursements</td>\n",
       "      <td>rhubarb</td>\n",
       "      <td>tsars</td>\n",
       "      <td>ktm</td>\n",
       "      <td>leonas</td>\n",
       "      <td>reductionism</td>\n",
       "      <td>abovethelawcom</td>\n",
       "      <td>outkast</td>\n",
       "      <td>maatschappij</td>\n",
       "      <td>noragami</td>\n",
       "      <td>scii</td>\n",
       "      <td>interceptors</td>\n",
       "      <td>reseda</td>\n",
       "      <td>transphobes</td>\n",
       "      <td>experimentalist</td>\n",
       "      <td>conneries</td>\n",
       "      <td>brigens</td>\n",
       "      <td>schlemko</td>\n",
       "      <td>yeaaahhh</td>\n",
       "      <td>behringer</td>\n",
       "      <td>euphoriajet</td>\n",
       "      <td>legitimize</td>\n",
       "      <td>upstaged</td>\n",
       "      <td>reato</td>\n",
       "      <td>displacement</td>\n",
       "      <td>kecleon</td>\n",
       "      <td>demotivating</td>\n",
       "      <td>cordura</td>\n",
       "      <td>fenharel</td>\n",
       "      <td>articolul</td>\n",
       "      <td>disciplina</td>\n",
       "      <td>xcode</td>\n",
       "      <td>kgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sisteri</td>\n",
       "      <td>cobran</td>\n",
       "      <td>ktb</td>\n",
       "      <td>hummingbirds</td>\n",
       "      <td>slid</td>\n",
       "      <td>mackey</td>\n",
       "      <td>bence</td>\n",
       "      <td>shunning</td>\n",
       "      <td>thingsa</td>\n",
       "      <td>brokengifs</td>\n",
       "      <td>skatten</td>\n",
       "      <td>ftherealmofmianite</td>\n",
       "      <td>sighi</td>\n",
       "      <td>copd</td>\n",
       "      <td>trinisphere</td>\n",
       "      <td>fafnir</td>\n",
       "      <td>nightyou</td>\n",
       "      <td>comptroller</td>\n",
       "      <td>hazelnuts</td>\n",
       "      <td>chechnya</td>\n",
       "      <td>kawasaki</td>\n",
       "      <td>malf</td>\n",
       "      <td>morality</td>\n",
       "      <td>homephp</td>\n",
       "      <td>buckethead</td>\n",
       "      <td>huidige</td>\n",
       "      <td>flcl</td>\n",
       "      <td>maplestory</td>\n",
       "      <td>demolisher</td>\n",
       "      <td>fremont</td>\n",
       "      <td>prudes</td>\n",
       "      <td>icepack</td>\n",
       "      <td>apparemment</td>\n",
       "      <td>dahinter</td>\n",
       "      <td>bonner</td>\n",
       "      <td>hahhaha</td>\n",
       "      <td>xt</td>\n",
       "      <td>jimrosenz</td>\n",
       "      <td>pacify</td>\n",
       "      <td>outmaneuvered</td>\n",
       "      <td>poteva</td>\n",
       "      <td>enthalpy</td>\n",
       "      <td>pumpkaboo</td>\n",
       "      <td>forgetable</td>\n",
       "      <td>chromexcel</td>\n",
       "      <td>elrond</td>\n",
       "      <td>noua</td>\n",
       "      <td>diminui</td>\n",
       "      <td>ghc</td>\n",
       "      <td>tqr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ladybits</td>\n",
       "      <td>defiende</td>\n",
       "      <td>zenit</td>\n",
       "      <td>hummingbird</td>\n",
       "      <td>heaved</td>\n",
       "      <td>jacobson</td>\n",
       "      <td>jau</td>\n",
       "      <td>attributing</td>\n",
       "      <td>thingsbut</td>\n",
       "      <td>oldpeoplefacebook</td>\n",
       "      <td>resurser</td>\n",
       "      <td>wlgif</td>\n",
       "      <td>ohi</td>\n",
       "      <td>warfarin</td>\n",
       "      <td>karakas</td>\n",
       "      <td>ammy</td>\n",
       "      <td>nite</td>\n",
       "      <td>dwp</td>\n",
       "      <td>chilies</td>\n",
       "      <td>georgian</td>\n",
       "      <td>transaxle</td>\n",
       "      <td>homeguards</td>\n",
       "      <td>arbitrariness</td>\n",
       "      <td>nicememewebsite</td>\n",
       "      <td>tdwp</td>\n",
       "      <td>vervolgens</td>\n",
       "      <td>akira</td>\n",
       "      <td>gow</td>\n",
       "      <td>torp</td>\n",
       "      <td>newmarket</td>\n",
       "      <td>cretins</td>\n",
       "      <td>altaholic</td>\n",
       "      <td>pleins</td>\n",
       "      <td>nliche</td>\n",
       "      <td>lohse</td>\n",
       "      <td>chryssyjuice</td>\n",
       "      <td>panasonic</td>\n",
       "      <td>iloveamericanpie</td>\n",
       "      <td>devalue</td>\n",
       "      <td>wooed</td>\n",
       "      <td>differenza</td>\n",
       "      <td>tensor</td>\n",
       "      <td>nidoking</td>\n",
       "      <td>unnerving</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>nerevar</td>\n",
       "      <td>serviciu</td>\n",
       "      <td>somente</td>\n",
       "      <td>btsync</td>\n",
       "      <td>gjm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>neice</td>\n",
       "      <td>amenazas</td>\n",
       "      <td>wsw</td>\n",
       "      <td>cuttlefish</td>\n",
       "      <td>slithered</td>\n",
       "      <td>kaye</td>\n",
       "      <td>kendini</td>\n",
       "      <td>sabotaging</td>\n",
       "      <td>disciplines</td>\n",
       "      <td>killthosewhodisagree</td>\n",
       "      <td>socialister</td>\n",
       "      <td>fnascar</td>\n",
       "      <td>howeveri</td>\n",
       "      <td>acidosis</td>\n",
       "      <td>tamiyo</td>\n",
       "      <td>rydia</td>\n",
       "      <td>ldac</td>\n",
       "      <td>ubs</td>\n",
       "      <td>kimchi</td>\n",
       "      <td>kmt</td>\n",
       "      <td>tdi</td>\n",
       "      <td>jannas</td>\n",
       "      <td>naturalism</td>\n",
       "      <td>whgov</td>\n",
       "      <td>motorhead</td>\n",
       "      <td>daarvoor</td>\n",
       "      <td>chiaki</td>\n",
       "      <td>swbf</td>\n",
       "      <td>svipul</td>\n",
       "      <td>arlington</td>\n",
       "      <td>nincompoops</td>\n",
       "      <td>upvoteedit</td>\n",
       "      <td>rapidement</td>\n",
       "      <td>manchmal</td>\n",
       "      <td>victorino</td>\n",
       "      <td>yeaahh</td>\n",
       "      <td>vtr</td>\n",
       "      <td>polskan</td>\n",
       "      <td>undermine</td>\n",
       "      <td>antagonized</td>\n",
       "      <td>messo</td>\n",
       "      <td>conductance</td>\n",
       "      <td>lapras</td>\n",
       "      <td>bullshitty</td>\n",
       "      <td>beading</td>\n",
       "      <td>mythal</td>\n",
       "      <td>altfel</td>\n",
       "      <td>exemplos</td>\n",
       "      <td>gvim</td>\n",
       "      <td>jzm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cluster #01  Cluster #02  Cluster #03   Cluster #04 Cluster #05  \\\n",
       "1        exwife      echando          csk        nymphs    slithers   \n",
       "2    tormentors     adecuada         mous         spiny      bobbed   \n",
       "3    ladyfriend      revisar   anderlecht     jellyfish     flapped   \n",
       "4       daugher  maravilloso      jaedong       lizards     wiggled   \n",
       "5     shipmates     tremenda  galatasaray      tadpoles      darted   \n",
       "6       wifeand    prioridad          huk     clownfish    scooting   \n",
       "7     friendyou      castigo     stephano      reindeer     bobbing   \n",
       "8       sexlife   electorado        fener  caterpillars    wiggling   \n",
       "9   stepbrother        mitad    villareal     squirrels     twirled   \n",
       "10        wifei     hacerles   fenerbahce          moth     flicked   \n",
       "11   bestfriend       pongan      momochi     tarantula   fluttered   \n",
       "12      motheri      reciben          skc      anemones  slithering   \n",
       "13      stepson   seguiremos    hungrybox         crabs    flicking   \n",
       "14      bodyand        fecha      mineski      tortoise   wriggling   \n",
       "15     soulmate    sobretodo     besiktas     dungeness    swishing   \n",
       "16    castmates     dignidad   ludogorets   dragonflies     darting   \n",
       "17      nmother        digna    lemondogs  grasshoppers      glided   \n",
       "18      sisteri       cobran          ktb  hummingbirds        slid   \n",
       "19     ladybits     defiende        zenit   hummingbird      heaved   \n",
       "20        neice     amenazas          wsw    cuttlefish   slithered   \n",
       "\n",
       "   Cluster #06 Cluster #07   Cluster #08      Cluster #09  \\\n",
       "1       benson       nedir   undermining      thingsthere   \n",
       "2        welch       cevap     belittles         oddballs   \n",
       "3        byrne       devam       pursues       thingsthey   \n",
       "4     connelly         eka       defends         oddities   \n",
       "5        mckay        olmu    denigrates  counterexamples   \n",
       "6        dunne        saat   disrespects          gotchas   \n",
       "7       siegel         amk     sabotages           thigns   \n",
       "8      mcgrath       degil   victimizing            afscs   \n",
       "9      delaney        yine    demonizing         usecases   \n",
       "10      farrar       fazla   dehumanizes             scps   \n",
       "11    clements       fakat     dismisses     thingspeople   \n",
       "12   dougherty       mieli  antagonizing         monikers   \n",
       "13     doherty        uzun    condemning        thingsnow   \n",
       "14      spence        olur   manipulates     knuckleheads   \n",
       "15      mccall        niye     vilifying         subjects   \n",
       "16       olson       belki   antagonizes           things   \n",
       "17     mcelroy       yoksa   mistreating     exbeeriments   \n",
       "18      mackey       bence      shunning          thingsa   \n",
       "19    jacobson         jau   attributing        thingsbut   \n",
       "20        kaye     kendini    sabotaging      disciplines   \n",
       "\n",
       "              Cluster #10   Cluster #11                   Cluster #12  \\\n",
       "1           mallninjashit     cyklister                    pltzjrhgif   \n",
       "2           swordorsheath        fyller                    dhmeazkgif   \n",
       "3    treessuckingonthings       idioter                    tjabjjlgif   \n",
       "4    subredditsashashtags      fortsatt                    drhiqrgifv   \n",
       "5              shubreddit    ordentligt                        drhiqr   \n",
       "6   theydidthemonstermath        staden                       imzhell   \n",
       "7      thingsjonsnowknows       metoder                    adibprojpg   \n",
       "8              girlsmirin         saken                      vwmingif   \n",
       "9       shittyanimalfacts    resultatet                   slcrftmbsgs   \n",
       "10            retiredgifs  kapitalismen                         yvviq   \n",
       "11        ooerintensifies     historien                     fruomifpw   \n",
       "12          natureismetal        delvis                    tqzgqegjpg   \n",
       "13   itwasagraveyardgraph        enormt                    wjanvcdjpg   \n",
       "14           lifeofnorman         vinst                    vqlgjolgif   \n",
       "15        humansbeingbros      konstant                    irspheerbj   \n",
       "16             retiredjpg       kroppen                  bennotronica   \n",
       "17              noisygifs    argumentet  consciousblankamericancicada   \n",
       "18             brokengifs       skatten            ftherealmofmianite   \n",
       "19      oldpeoplefacebook      resurser                         wlgif   \n",
       "20   killthosewhodisagree   socialister                       fnascar   \n",
       "\n",
       "   Cluster #13      Cluster #14     Cluster #15 Cluster #16    Cluster #17  \\\n",
       "1      thanksi        secretion      warbringer        weap        nightso   \n",
       "2        dudei  corticosteroids      rattleclaw    godsword        nightit   \n",
       "3         heyi     hypertension      stoneforge       vagan       nightbut   \n",
       "4      hahahai   corticosteroid        rakshasa    masamune      nightthis   \n",
       "5         yesi     isotretinoin     nighthowler        veng          edcny   \n",
       "6         yeai            cipro    gravekeepers     danjuro      nightalso   \n",
       "7     youstill       idiopathic        banefire        tyro       nightand   \n",
       "8        matei     hypoglycemia       thragtusk       weaps      nightedit   \n",
       "9         broi             etoh            wyrm     ukanlos        bonaroo   \n",
       "10       bruhi     inflammation    spellbreaker       hadar          edclv   \n",
       "11     ireally        urticaria          smiter        rath         otakon   \n",
       "12    exactlyi         curcumin       evilswarm   chameleos            gbo   \n",
       "13         xdi        estrogens        deciever      shotel        campout   \n",
       "14         uhi    acetaminophen  recombobulator  emberblade       nightfor   \n",
       "15     thatlol           reflux        felguard   soultaker  tomorrowworld   \n",
       "16        yupi    hyperglycemia    manamorphose     zanbato           pmso   \n",
       "17       whoai        sinusitis       soulshift     ceadeus      dragoncon   \n",
       "18       sighi             copd     trinisphere      fafnir       nightyou   \n",
       "19         ohi         warfarin         karakas        ammy           nite   \n",
       "20    howeveri         acidosis          tamiyo       rydia           ldac   \n",
       "\n",
       "       Cluster #18 Cluster #19   Cluster #20  Cluster #21 Cluster #22  \\\n",
       "1             hmrc  buttermilk     rhineland     fastback    bellonas   \n",
       "2       commission        curd     macedonia      hardtop       gnars   \n",
       "3           fincen        soya     jordanian          cyl       meele   \n",
       "4              ird      wasabi         burma         mkiv       udyrs   \n",
       "5             cmhc   buckwheat     sultanate      peugeot      swains   \n",
       "6     underwriting  applesauce    macedonian    silverado        ulty   \n",
       "7             icbc    jalapeno       mughals     wrangler     dravens   \n",
       "8        financing     chutney      rhodesia        supra       trynd   \n",
       "9   superannuation    jalepeno        kyrgyz         hemi     serqets   \n",
       "10            fdic     edamame        yemeni         gsxr        sylv   \n",
       "11        insurers      sorbet       algeria         busa        ulti   \n",
       "12       comission   pistachio        punjab       ducati        kogs   \n",
       "13             irs   cornbread    zapatistas  landcruiser   malzahars   \n",
       "14        treasury      cashew  czechoslovak  powerstroke   katarinas   \n",
       "15             hhs     tabasco       kashmir    sportster      yasuos   \n",
       "16     liquidation    habanero       armenia         kawi    kalistas   \n",
       "17   disbursements     rhubarb         tsars          ktm      leonas   \n",
       "18     comptroller   hazelnuts      chechnya     kawasaki        malf   \n",
       "19             dwp     chilies      georgian    transaxle  homeguards   \n",
       "20             ubs      kimchi           kmt          tdi      jannas   \n",
       "\n",
       "          Cluster #23           Cluster #24    Cluster #25     Cluster #26  \\\n",
       "1         materialism           archivehtml  badbadnotgood        trouwens   \n",
       "2           scientism              dxdoiorg     thundercat         slechts   \n",
       "3   conceptualization  didthemarinerswincom          bjork         gebeurt   \n",
       "4          praxeology          blognavercom       yelawolf         meestal   \n",
       "5            nihilism  inceptiondavepeducom      bangarang           eruit   \n",
       "6           dialectic               blogcom          qotsa           vaker   \n",
       "7        universality  momspaghettiytmndcom    madvillainy          aardig   \n",
       "8           amorality              mainhtml         motown          gedrag   \n",
       "9         nonviolence          fontsspddlde           kygo          ouders   \n",
       "10      postmodernism    feedsfeedburnercom           zedd       aangezien   \n",
       "11       subjectivism            wwwbashorg          flylo           neemt   \n",
       "12           fatalism     instantostrichcom         avicii      ontzettend   \n",
       "13          dogmatism                 kckst        nujabes   daadwerkelijk   \n",
       "14         dialectics         embedgyazocom      blackmill          ergens   \n",
       "15         empiricism       thatsthejokenet        deadmau  waarschijnlijk   \n",
       "16        physicalism                nonref         wavves          ineens   \n",
       "17       reductionism        abovethelawcom        outkast    maatschappij   \n",
       "18           morality               homephp     buckethead         huidige   \n",
       "19      arbitrariness       nicememewebsite           tdwp      vervolgens   \n",
       "20         naturalism                 whgov      motorhead        daarvoor   \n",
       "\n",
       "   Cluster #27   Cluster #28   Cluster #29 Cluster #30    Cluster #31  \\\n",
       "1        ranma  awesomenauts       missles   riverside          cucks   \n",
       "2      gintoki          homm    grenadiers     hampden     misogynist   \n",
       "3       gosick           nwn       javelin    lakewood   mysoginistic   \n",
       "4     xxxholic    skullgirls      ballista     decatur     tumblerina   \n",
       "5   idolmaster          dcuo      miniguns    pasadena     humourless   \n",
       "6       adachi     titanfall     decimator     ashland       trannies   \n",
       "7    takahashi      firefall    machinegun   lexington        libtard   \n",
       "8         saki      terraria       needler  charleston       feminazi   \n",
       "9        gantz      archeage      skyguard      acadia   misanthropes   \n",
       "10     yoshiki       nosgoth         recce    piedmont       dudebros   \n",
       "11    inuyasha       tropico    broadsides   waterford      xenophobe   \n",
       "12     chobits      mabinogi    autocannon     alameda    hatemongers   \n",
       "13       kaiki          teso      gunboats   edgewater  douchenozzles   \n",
       "14     shinobu         wakfu       minigun   grandview       douchbag   \n",
       "15      shizuo    helldivers      chaingun   lafayette      feminazis   \n",
       "16    dekomori       exanima         melta     norfolk    misogynists   \n",
       "17    noragami          scii  interceptors      reseda    transphobes   \n",
       "18        flcl    maplestory    demolisher     fremont         prudes   \n",
       "19       akira           gow          torp   newmarket        cretins   \n",
       "20      chiaki          swbf        svipul   arlington    nincompoops   \n",
       "\n",
       "         Cluster #32    Cluster #33   Cluster #34 Cluster #35  \\\n",
       "1           ambigram         valeur     ebenfalls      besler   \n",
       "2        antipattern        lalcool     verfahren       coyle   \n",
       "3               lpwo         choisi    wenigstens      boozer   \n",
       "4         antivaxxer         suivre       niemals      briere   \n",
       "5           idiotbut          lacte       dennoch       haula   \n",
       "6        assholealso         devait        jedoch  wisniewski   \n",
       "7   overexaggeration       vacances        daraus     cassels   \n",
       "8           antijoke         tudier        ndlich       osuna   \n",
       "9          idiotalso        hension        ebenso     coghlan   \n",
       "10     underachiever  gouvernements    vollkommen       kaman   \n",
       "11          ambivert       rarement   anscheinend     montero   \n",
       "12        assholebut          suivi   moderatoren      lofton   \n",
       "13              lise      largement      immerhin    henrique   \n",
       "14       exageration          faute     weiterhin    callahan   \n",
       "15             lisis         essaye  deutschlands    mccarron   \n",
       "16            injoke        ouverte  mittlerweile     brodeur   \n",
       "17   experimentalist      conneries       brigens    schlemko   \n",
       "18           icepack    apparemment      dahinter      bonner   \n",
       "19         altaholic         pleins        nliche       lohse   \n",
       "20        upvoteedit     rapidement      manchmal   victorino   \n",
       "\n",
       "        Cluster #36 Cluster #37        Cluster #38  Cluster #39  \\\n",
       "1          hahahaah     turnigy           catainia      confine   \n",
       "2             yaaaa       frsky      wpintheshower       expose   \n",
       "3        ohhhhhhhhh       sanyo           xgykbfcd     supplant   \n",
       "4              ayye         jvc             gijose  rationalise   \n",
       "5            yaaaaa      boscam  ellesarisellendil    constrain   \n",
       "6             nawww        emax           deckwash    verbalize   \n",
       "7            yooooo     kenwood            japface      subvert   \n",
       "8          ooohhhhh       denon          deeprocks      satisfy   \n",
       "9          yeaaaaah         vrx      michaelconfoy    weaponize   \n",
       "10         ayyyyyyy    spektrum        vinciisdead    eradicate   \n",
       "11  ahahahahahahaha         vsr        brazilsamba  desensitize   \n",
       "12          yeaahhh    lumenier        tortoisesex    overwhelm   \n",
       "13            yeeee   monoprice       feckingshite        expel   \n",
       "14             aaaw         cdj     stalkingbutler  micromanage   \n",
       "15            yeeah        teac           nappyzap     outsmart   \n",
       "16            yeaah         vtx          hossannna     persuade   \n",
       "17         yeaaahhh   behringer        euphoriajet   legitimize   \n",
       "18          hahhaha          xt          jimrosenz       pacify   \n",
       "19     chryssyjuice   panasonic   iloveamericanpie      devalue   \n",
       "20           yeaahh         vtr            polskan    undermine   \n",
       "\n",
       "      Cluster #40  Cluster #41   Cluster #42 Cluster #43     Cluster #44  \\\n",
       "1     eviscerated      appunto  oscillations   druddigon   interestingit   \n",
       "2         savaged       peggio      redshift      noibat      offputting   \n",
       "3       overtaken      diritto     diffusion      slugma    importantbut   \n",
       "4    cannibalized    mantenere  perturbation   spiritomb       commonand   \n",
       "5         hounded       figlio           cmb     moltres  unproffesional   \n",
       "6          bested  soprattutto  spectroscopy      audino         irksome   \n",
       "7        outvoted      scienza   capacitance     dedenne   importantedit   \n",
       "8       intimated      diverso        scalar   heracross     believeable   \n",
       "9     cockblocked      attivit  quantization   girafarig  interestingits   \n",
       "10      squelched        spesa     conformal   wobbuffet       annoyingi   \n",
       "11        courted      diciamo   convolution     tropius      neckbeardy   \n",
       "12        waylaid     pensiero  conductivity   cyndaquil      boringedit   \n",
       "13       assailed    posizione      emission     seviper    difficultand   \n",
       "14       repelled    immigrati     invariant      seedot    accuratealso   \n",
       "15     supplanted      attuale        cyclic    zangoose    disapointing   \n",
       "16        flogged    piuttosto    covariance   crawdaunt           niave   \n",
       "17       upstaged        reato  displacement     kecleon    demotivating   \n",
       "18  outmaneuvered       poteva      enthalpy   pumpkaboo      forgetable   \n",
       "19          wooed   differenza        tensor    nidoking       unnerving   \n",
       "20    antagonized        messo   conductance      lapras      bullshitty   \n",
       "\n",
       "    Cluster #45 Cluster #46 Cluster #47    Cluster #48  Cluster #49  \\\n",
       "1      pleather     flemeth     noastre         chegou         nmap   \n",
       "2      neoprene    odysseus       acasa       mestrado       plugin   \n",
       "3        beaded     boromir      incepe    conseguiram  commandline   \n",
       "4     ultrafine     mordred      undeva          noite        xampp   \n",
       "5       cowhide     moqorro      tocmai         acabou       winscp   \n",
       "6       peacoat     faramir     acestea          fugir         libc   \n",
       "7         tulle   conquerer       scurt          risco        dmenu   \n",
       "8       goretex       circe     noaptea  profissionais      openssl   \n",
       "9   rhinestones       eowyn      totusi      estudante     robocopy   \n",
       "10      ripstop     saruman     cuvinte         roubar       sqlite   \n",
       "11      quilted       grima    asemenea          levam          sdl   \n",
       "12        linen     rheagar     vorbesc        animais          cli   \n",
       "13       mohair        gwyn       scriu          feita      builtin   \n",
       "14       pewter     craster      oricum          ficou         qgis   \n",
       "15       nubuck      moriah  experienta     entretanto      dirsync   \n",
       "16      selvage     gandalf     altceva  criminalidade         tftp   \n",
       "17      cordura    fenharel   articolul     disciplina        xcode   \n",
       "18   chromexcel      elrond        noua        diminui          ghc   \n",
       "19      chiffon     nerevar    serviciu        somente       btsync   \n",
       "20      beading      mythal      altfel       exemplos         gvim   \n",
       "\n",
       "   Cluster #50  \n",
       "1          rzg  \n",
       "2          zbc  \n",
       "3          oyz  \n",
       "4          vww  \n",
       "5          qhw  \n",
       "6          vyt  \n",
       "7          qgc  \n",
       "8          zja  \n",
       "9          gjq  \n",
       "10         qjx  \n",
       "11         qln  \n",
       "12         qfw  \n",
       "13         rzp  \n",
       "14         hzy  \n",
       "15         vqu  \n",
       "16         qqj  \n",
       "17         kgh  \n",
       "18         tqr  \n",
       "19         gjm  \n",
       "20         jzm  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_cloud(cluster_num, cmap):\n",
    "    wc = WordCloud(background_color=\"black\", max_words=2000, max_font_size=80, colormap=cmap);\n",
    "    wordcloud = wc.generate(' '.join([word for word in top_words['Cluster #' + str(cluster_num).zfill(2)]]))\n",
    "\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig('cluster_' + str(cluster_num), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmaps = cycle([\n",
    "            'flag', 'prism', 'ocean', 'gist_earth', 'terrain', 'gist_stern',\n",
    "            'gnuplot', 'gnuplot2', 'CMRmap', 'cubehelix', 'brg', 'hsv',\n",
    "            'gist_rainbow', 'rainbow', 'jet', 'nipy_spectral', 'gist_ncar'])\n",
    "\n",
    "for i in range(50):\n",
    "    col = next(cmaps);\n",
    "    display_cloud(i+1, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What else can we do with Word Vectors? Gensim provides some built in functions for us to play with. We can use analogies to see word associations. For instance, King is to Woman as Queen is to _ , we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_table(table, key, sim_key='similarity', show_sim = True):\n",
    "    if show_sim == True:\n",
    "        return pd.DataFrame(table, columns=[key, sim_key])\n",
    "    else:\n",
    "        return pd.DataFrame(table, columns=[key, sim_key])[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analogy</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gentleman</td>\n",
       "      <td>0.862861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>man</td>\n",
       "      <td>0.811435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>murderer</td>\n",
       "      <td>0.809090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>felon</td>\n",
       "      <td>0.808202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>policeman</td>\n",
       "      <td>0.808161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cop</td>\n",
       "      <td>0.802881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>guy</td>\n",
       "      <td>0.800012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>conman</td>\n",
       "      <td>0.799367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zimmerman</td>\n",
       "      <td>0.799187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lawman</td>\n",
       "      <td>0.796910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Analogy  similarity\n",
       "0  gentleman    0.862861\n",
       "1        man    0.811435\n",
       "2   murderer    0.809090\n",
       "3      felon    0.808202\n",
       "4  policeman    0.808161\n",
       "5        cop    0.802881\n",
       "6        guy    0.800012\n",
       "7     conman    0.799367\n",
       "8  zimmerman    0.799187\n",
       "9     lawman    0.796910"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_table(model.wv.most_similar_cosmul(positive=['king', 'woman'], negative=['queen']), 'Analogy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although 'man' is not the first keyword here, some of the other words also fall in the same category.\n",
    "\n",
    "We can also use Word2Vec to find the word that doesn't match the context of other words in a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tesla'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"apple microsoft samsung tesla\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trump'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"trump clinton sanders obama\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jon'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"joffrey cersei tywin lannister jon\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'viserion'"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"daenerys rhaegar viserion aemon aegon jon targaryen\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use Word Vectors to find words that are closest to the target by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = ['musk', 'modi', 'hodor', 'martell', 'apple', 'neutrality', 'snowden', 'batman', 'hulk', 'warriors', 'falcons', 'pizza', ];\n",
    "tables = [];\n",
    "for key in keys:\n",
    "    tables.append(get_word_table(model.wv.similar_by_word(key), key, show_sim=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>musk</th>\n",
       "      <th>modi</th>\n",
       "      <th>hodor</th>\n",
       "      <th>martell</th>\n",
       "      <th>apple</th>\n",
       "      <th>neutrality</th>\n",
       "      <th>snowden</th>\n",
       "      <th>batman</th>\n",
       "      <th>hulk</th>\n",
       "      <th>warriors</th>\n",
       "      <th>falcons</th>\n",
       "      <th>pizza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elon</td>\n",
       "      <td>narendra</td>\n",
       "      <td>meera</td>\n",
       "      <td>mormont</td>\n",
       "      <td>iwatch</td>\n",
       "      <td>criminalisation</td>\n",
       "      <td>whistleblower</td>\n",
       "      <td>superman</td>\n",
       "      <td>thor</td>\n",
       "      <td>rangers</td>\n",
       "      <td>ravens</td>\n",
       "      <td>burger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>musks</td>\n",
       "      <td>kejriwal</td>\n",
       "      <td>coldhands</td>\n",
       "      <td>tully</td>\n",
       "      <td>android</td>\n",
       "      <td>ttip</td>\n",
       "      <td>assange</td>\n",
       "      <td>deadpool</td>\n",
       "      <td>superman</td>\n",
       "      <td>hawks</td>\n",
       "      <td>panthers</td>\n",
       "      <td>sandwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tesla</td>\n",
       "      <td>bjp</td>\n",
       "      <td>bloodraven</td>\n",
       "      <td>baratheon</td>\n",
       "      <td>blackberry</td>\n",
       "      <td>decentralization</td>\n",
       "      <td>wikileaks</td>\n",
       "      <td>spiderman</td>\n",
       "      <td>aquaman</td>\n",
       "      <td>wizards</td>\n",
       "      <td>bengals</td>\n",
       "      <td>burrito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solarcity</td>\n",
       "      <td>arvind</td>\n",
       "      <td>benjen</td>\n",
       "      <td>arryn</td>\n",
       "      <td>iphone</td>\n",
       "      <td>privatization</td>\n",
       "      <td>snowdens</td>\n",
       "      <td>joker</td>\n",
       "      <td>spiderman</td>\n",
       "      <td>grizzlies</td>\n",
       "      <td>broncos</td>\n",
       "      <td>mcchicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nikola</td>\n",
       "      <td>netanyahu</td>\n",
       "      <td>sarella</td>\n",
       "      <td>greyjoy</td>\n",
       "      <td>huawei</td>\n",
       "      <td>redistribution</td>\n",
       "      <td>nsa</td>\n",
       "      <td>wolverine</td>\n",
       "      <td>wolverine</td>\n",
       "      <td>clippers</td>\n",
       "      <td>rams</td>\n",
       "      <td>chipotle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bezos</td>\n",
       "      <td>poroshenko</td>\n",
       "      <td>wylla</td>\n",
       "      <td>elia</td>\n",
       "      <td>motorola</td>\n",
       "      <td>corruption</td>\n",
       "      <td>binney</td>\n",
       "      <td>aquaman</td>\n",
       "      <td>magneto</td>\n",
       "      <td>giants</td>\n",
       "      <td>cowboys</td>\n",
       "      <td>bagel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wozniak</td>\n",
       "      <td>javid</td>\n",
       "      <td>patchface</td>\n",
       "      <td>lannister</td>\n",
       "      <td>crapple</td>\n",
       "      <td>reform</td>\n",
       "      <td>whistleblowers</td>\n",
       "      <td>nightwing</td>\n",
       "      <td>drax</td>\n",
       "      <td>raiders</td>\n",
       "      <td>steelers</td>\n",
       "      <td>steak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>woz</td>\n",
       "      <td>smriti</td>\n",
       "      <td>sweetrobin</td>\n",
       "      <td>frey</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>censorship</td>\n",
       "      <td>cia</td>\n",
       "      <td>deathstroke</td>\n",
       "      <td>deadpool</td>\n",
       "      <td>titans</td>\n",
       "      <td>seahawks</td>\n",
       "      <td>kfc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spacex</td>\n",
       "      <td>modiji</td>\n",
       "      <td>bran</td>\n",
       "      <td>rhaenys</td>\n",
       "      <td>urbane</td>\n",
       "      <td>bipartisan</td>\n",
       "      <td>gchq</td>\n",
       "      <td>daredevil</td>\n",
       "      <td>namor</td>\n",
       "      <td>bulls</td>\n",
       "      <td>packers</td>\n",
       "      <td>falafel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>buffett</td>\n",
       "      <td>jaitley</td>\n",
       "      <td>craster</td>\n",
       "      <td>tyrell</td>\n",
       "      <td>micromax</td>\n",
       "      <td>regulation</td>\n",
       "      <td>obama</td>\n",
       "      <td>punisher</td>\n",
       "      <td>malekith</td>\n",
       "      <td>cavs</td>\n",
       "      <td>sabres</td>\n",
       "      <td>bagels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        musk        modi       hodor    martell       apple        neutrality  \\\n",
       "0       elon    narendra       meera    mormont      iwatch   criminalisation   \n",
       "1      musks    kejriwal   coldhands      tully     android              ttip   \n",
       "2      tesla         bjp  bloodraven  baratheon  blackberry  decentralization   \n",
       "3  solarcity      arvind      benjen      arryn      iphone     privatization   \n",
       "4     nikola   netanyahu     sarella    greyjoy      huawei    redistribution   \n",
       "5      bezos  poroshenko       wylla       elia    motorola        corruption   \n",
       "6    wozniak       javid   patchface  lannister     crapple            reform   \n",
       "7        woz      smriti  sweetrobin       frey   microsoft        censorship   \n",
       "8     spacex      modiji        bran    rhaenys      urbane        bipartisan   \n",
       "9    buffett     jaitley     craster     tyrell    micromax        regulation   \n",
       "\n",
       "          snowden       batman       hulk   warriors   falcons      pizza  \n",
       "0   whistleblower     superman       thor    rangers    ravens     burger  \n",
       "1         assange     deadpool   superman      hawks  panthers   sandwich  \n",
       "2       wikileaks    spiderman    aquaman    wizards   bengals    burrito  \n",
       "3        snowdens        joker  spiderman  grizzlies   broncos  mcchicken  \n",
       "4             nsa    wolverine  wolverine   clippers      rams   chipotle  \n",
       "5          binney      aquaman    magneto     giants   cowboys      bagel  \n",
       "6  whistleblowers    nightwing       drax    raiders  steelers      steak  \n",
       "7             cia  deathstroke   deadpool     titans  seahawks        kfc  \n",
       "8            gchq    daredevil      namor      bulls   packers    falafel  \n",
       "9           obama     punisher   malekith       cavs    sabres     bagels  "
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(tables, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results show how effective Word Vectors are in understanding context between words. We see that the algorithm is easily able to identify words that are based on similar concepts, even though they are less likely to appear in the same sentences. The reason for this is because these words are more likely to have similar labels, which forces their vectors to train into values that can predict those labels correctly.\n",
    "\n",
    "These results show how effective Word Vectors are in understanding context between words. We can see that the model is easily able to find names of other people commonly associated with \"Elon Musk\" in the first column, or those associated with the Indian Prime Minister Modi in the 2nd column. \n",
    "\n",
    "In keeping with the Game of Thrones theme, when I pass in \"Hodor\", we see the names of other people from the North like Benjen, Bran, Meera, and Craster, but passing in \"Martell\" gives names of other houses in Westeros instead like Mormont and Tully.\n",
    "\n",
    "The word \"Neutrality\" shows some interesting results, words that describe how Reddit feels about Net Neutrality, such as with \"privatization\", \"censorship\", and \"ttip\" (the Transatlantic trade and investment partnership), and \"Snowden\" has words like whistleblower, assange, and nsa.\n",
    "\n",
    "Just for fun, we see the names of other superheroes when we pass in \"batman\" and \"hulk\", although there is more overlap of Marvel heroes in the first list than there is of DC heroes in the second one.\n",
    "\n",
    "Passing in the name of an NBA team and NFL team gives back other teams in the leagues, and \"Pizza\" just gives back other food names."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
